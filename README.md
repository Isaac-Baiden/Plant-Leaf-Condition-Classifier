# Plant-Leaf-Condition-Classifier
This project uses a Vision Transformer (ViT) model to classify plant leaf conditions into various categories such as healthy leaves and diseased leaves. The model is trained on a variety of plant species and their common diseases. After classification, the app provides actionable mitigation strategies to help treat or manage the disease.

Project Notes
Technology Used: Streamlit for the app, TensorFlow for the model, and OpenCV for image processing.
Model Type: Vision Transformer (ViT) trained on a dataset of plant leaf images.
Key Features:
Classify plant leaf conditions.
Suggest mitigation or treatment strategies.
Ensure good image quality (sharpness, lighting, contrast) for accurate predictions.

‚Ä¢	Main Function (main()):

o	Sets the page configuration and title.
o	Loads the model using load_keras_model().
o	Provides instructions for enabling camera access.
o	Handles image input from both file uploads and the camera.
o	Displays the uploaded image.
o	Performs image quality checks.
o	Predicts the class using the loaded model.
o	Displays the prediction, confidence, and mitigation strategy.
o	Saves the image and logs the prediction.
o	Includes a sidebar with project information.
o	Adds project overview to the main body.

I wish to further refine the entire project.

Isaac Baiden

isaac.baiden.stu@uenr.edu.gh

isbaiden.fx@gmail.com

+233 20 8775507

University of Ernergy and Natural Resources, 

Sunyani Ghana

================================================================================
===============================================================================
Dataset  Data for: Identification of Plant Leaf Diseases Using a 9-layer Deep Convolutional Neural Network - Mendeley Data
J, ARUN PANDIAN; GOPAL, GEETHARAMANI (2019), ‚ÄúData for: Identification of Plant Leaf Diseases Using a 9-layer Deep Convolutional Neural Network‚Äù, Mendeley Data, V1, doi: 10.17632/tywbtsjrjv.1
üìä Preprocessing
‚Ä¢	Resizing to 64x64
‚Ä¢	Normalization to [0, 1]
‚Ä¢	Data Augmentation : flipping, rotation
‚Ä¢	Split: 70% training, 15% validation, 15% testing
________________________________________
üß† 2. Model Architecture: Vision Transformer (ViT)
‚öôÔ∏è Configuration
‚Ä¢	Patch Size: 8
‚Ä¢	Embedding Dimension: 64
‚Ä¢	Attention Heads: 2
‚Ä¢	Transformer Layers: 2
‚Ä¢	Dropout Rate: 0.3
‚Ä¢	Classifier: MLP with two Dense layers
üß© Custom Layers
A custom PatchExtract layer was defined using tf.image.extract_patches to split images into patches and embed them for attention computation.
üèãÔ∏è Training
‚Ä¢	Optimizer: Adam (learning rate = 1e-4)
‚Ä¢	Loss Function: Categorical Crossentropy
‚Ä¢	Epochs: 200
‚Ä¢	Metrics: Accuracy
The model achieved high accuracy on both training and validation sets, outperforming traditional CNN-based baselines.
________________________________________
üíª 3. Web Application with Streamlit
A lightweight, interactive Streamlit app was built to:
‚Ä¢	Upload or capture leaf images using the device camera.
‚Ä¢	Run real-time predictions using the trained ViT model.
‚Ä¢	Display:
o	Predicted disease class
o	Confidence score
o	Recommended treatment strategy
‚Ä¢	Store predictions and images in a local log with timestamps.
üß† Smart Quality Checks:
Before prediction, the app evaluates:
‚Ä¢	Blurriness
‚Ä¢	Lighting
‚Ä¢	Contrast
If poor quality is detected, the user is notified to retake or upload a better image.
________________________________________
üöÄ 4. Deployment
The app is designed for easy deployment:
‚Ä¢	Lightweight frontend via Streamlit
‚Ä¢	TensorFlow/Keras backend for inference
‚Ä¢	Ready for deployment on:
o	Streamlit Cloud
o	Local LAN/Web server
üîê Additional Features:
‚Ä¢	Model loading with custom objects
‚Ä¢	CSV Logging of predictions
‚Ä¢	Mitigation strategy database
‚Ä¢	Webcam or file upload support
________________________________________
‚úÖ Outcome
‚Ä¢	Fast, accurate disease detection (real-time).
‚Ä¢	Helps farmers act quickly to prevent spread.
‚Ä¢	Intuitive interface requiring no technical expertise.
‚Ä¢	Easily extendable to new crops or diseases.
________________________________________
üîÆ Future Work
‚Ä¢	Integrate with IoT sensors for real-time farm monitoring.
‚Ä¢	Add multi-language support for accessibility.
‚Ä¢	Train a mobile-optimized lightweight model for offline use.


